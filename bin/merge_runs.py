import os
import click
import qiime2
import logging
import multiprocessing

import pandas as pd

from qiime2.plugins import feature_table

from .qiime2_pipeline import *


def merge_run_tables(table1_artifact_path, table2_artifact_path):
    table1 = load_data_artifact(table1_artifact_path)
    table2 = load_data_artifact(table2_artifact_path)
    dada2_filtered_table = feature_table.actions.merge(table1=table1, table2=table2).merged_table
    return dada2_filtered_table


def merge_run_repseqs(repseqs1_artifact_path, repseqs2_artifact_path):
    repseqs1 = load_data_artifact(repseqs1_artifact_path)
    repseqs2 = load_data_artifact(repseqs2_artifact_path)
    dada2_filtered_rep_seqs = feature_table.actions.merge_seq_data(repseqs1, repseqs2).merged_data
    return dada2_filtered_rep_seqs

'''
TODO: https://docs.qiime2.org/2017.12/plugins/available/feature-table/filter-samples/
Must pass the <metadata> and <where> parameters to the filter-samples function in order to filter properly. 

My guess is that I'll need to do the following 'where' statement:
"sample sub-type = 'Sprouts'"

'''

def filter_run_tables():
    pass

def filter_run_repseqs():
    pass


@click.command()
@click.option('-b', '--base_dir',
              type=click.Path(exists=False),
              required=True,
              help='Base directory for all output from QIIME2-MERGE Pipeline.')
@click.option('-m', '--sample_metadata_path',
              type=click.Path(exists=True),
              required=True,
              help='Path to QIIME2 tab-separated metadata file')
@click.option('-c', '--classifier_artifact_path',
              type=click.Path(exists=True),
              required=True,
              help='Path to QIIME2 Classifier Artifact')
@click.option('-t1', '--table1_artifact_path',
              type=click.Path(exists=True),
              required=True,
              help='Path to first table artifact generated by DADA2 for merging')
@click.option('-t2', '--table2_artifact_path',
              type=click.Path(exists=True),
              required=True,
              help='Path to second table artifact generated by DADA2 for merging')
@click.option('-rs1', '--repseqs1_artifact_path',
              type=click.Path(exists=True),
              required=True,
              help='Path to first representative sequences artifact generated by DADA2 for merging')
@click.option('-rs2', '--repseqs2_artifact_path',
              type=click.Path(exists=True),
              required=True,
              help='Path to second representative sequences artifact generated by DADA2 for merging')
@click.option('-f', '--filtering_criteria',
              help='Criteria to filter metadata and subsequent downstream analysis')
def run_merge_pipeline(base_dir,
                       sample_metadata_path,
                       classifier_artifact_path,
                       table1_artifact_path,
                       table2_artifact_path,
                       repseqs1_artifact_path,
                       repseqs2_artifact_path):
    """
    1. Load and merge dada2 results from two previous runs
    2. Multiple sequence alignment and masking of highly variable regions
    3. Generate a phylogenetic tree
    4. Load an existing qiime2 classifier artifact
    5. Generate alpha rarefaction curves
    6. Conduct taxonomic analysis
    7. Generate taxonomy barplots
    8. Run diversity metrics

    :param base_dir: Main working directory filepath
    :param data_artifact_path:
    :param sample_metadata_path:
    :param classifier_artifact_path:
    """
    # Load metadata
    metadata_object = load_sample_metadata(sample_metadata_path)

    # Merge runs
    dada2_filtered_table = merge_run_tables(table1_artifact_path, table2_artifact_path)
    dada2_filtered_rep_seqs = merge_run_repseqs(repseqs1_artifact_path, repseqs2_artifact_path)

    # Continue pipeline as normal
    # Visualize dada2
    feature_table_summary = visualize_dada2(base_dir=base_dir,
                                            dada2_filtered_table=dada2_filtered_table,
                                            dada2_filtered_rep_seqs=dada2_filtered_rep_seqs,
                                            metadata_object=metadata_object)

    # Mask and alignment
    (seq_mask, seq_alignment) = seq_alignment_mask(base_dir=base_dir,
                                                   dada2_filtered_rep_seqs=dada2_filtered_rep_seqs)

    # Phylogenetic tree
    (phylo_unrooted_tree, phylo_rooted_tree) = phylo_tree(base_dir=base_dir, seq_mask=seq_mask)

    # Export tree
    export_newick(base_dir=base_dir, tree=phylo_rooted_tree)

    # Load classifier
    classifier = load_classifier_artifact(classifier_artifact_path=classifier_artifact_path)

    # Produce rarefaction visualization
    alpha_rarefaction_viz = alpha_rarefaction_visualization(base_dir=base_dir,
                                                            dada2_filtered_table=dada2_filtered_table)

    # Run taxonomic analysis
    taxonomy_analysis = classify_taxonomy(base_dir=base_dir,
                                          dada2_filtered_rep_seqs=dada2_filtered_rep_seqs,
                                          classifier=classifier)

    # Visualize taxonomy
    taxonomy_metadata = visualize_taxonomy(base_dir=base_dir,
                                           metadata_object=metadata_object,
                                           taxonomy_analysis=taxonomy_analysis,
                                           dada2_filtered_table=dada2_filtered_table)

    # Alpha and beta diversity
    diversity_metrics = run_diversity_metrics(base_dir=base_dir,
                                              dada2_filtered_table=dada2_filtered_table,
                                              phylo_rooted_tree=phylo_rooted_tree,
                                              metadata_object=metadata_object)

if __name__ == '__main__':
    run_merge_pipeline()
